{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "df = spark.read.load('abfss://sampledataset@##Replace##.dfs.core.windows.net/nyctaxi/NYCTripSmall.parquet', format='parquet')\r\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "from datetime import datetime\r\n",
        "from pyspark.sql.functions import *\r\n",
        "\r\n",
        "# To make development easier, faster, and less expensive, downsample for now\r\n",
        "sampled_taxi_df = df\r\n",
        "\r\n",
        "taxi_df = sampled_taxi_df.select('PassengerCount', 'TripDistanceMiles',  'PickupLongitude', 'PickupLatitude', 'DropoffLongitude', 'DropoffLatitude', 'PaymentType', 'FareAmount', 'TipAmount')\r\n",
        "taxi_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Random split dataset using Spark; convert Spark to pandas\r\n",
        "training_data, validation_data = taxi_df.randomSplit([0.8,0.2], 223)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Enter your workspace subscription, resource group, name, and region.\r\n",
        "subscription_id = \"##Replace##\" #you should be owner or contributor\r\n",
        "resource_group = \"##Replace##\" #you should be owner or contributor\r\n",
        "workspace_name = \"##Replace##\" #your workspace name\r\n",
        "# workspace_region = \"<enter workspace region>\" #your region\r\n",
        "\r\n",
        "ws = Workspace(workspace_name = workspace_name,\r\n",
        "               subscription_id = subscription_id,\r\n",
        "               resource_group = resource_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "import pandas \r\n",
        "from azureml.core import Dataset\r\n",
        "\r\n",
        "# Get the Azure Machine Learning default datastore\r\n",
        "datastore = ws.get_default_datastore()\r\n",
        "training_pd = training_data.toPandas().to_csv('training_pd.csv', index=False)\r\n",
        "\r\n",
        "# Convert into an Azure Machine Learning tabular dataset\r\n",
        "datastore.upload_files(files = ['training_pd.csv'],\r\n",
        "                       target_path = 'train-dataset/tabular/',\r\n",
        "                       overwrite = True,\r\n",
        "                       show_progress = True)\r\n",
        "dataset_training = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-dataset/tabular/training_pd.csv')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "import logging\r\n",
        "\r\n",
        "automl_settings = {\r\n",
        "    \"iteration_timeout_minutes\": 1, # It's just for workshop only\r\n",
        "    \"experiment_timeout_minutes\": 15, # It's just for workshop only\r\n",
        "    \"enable_early_stopping\": True,\r\n",
        "    \"primary_metric\": 'r2_score',\r\n",
        "    \"featurization\": 'auto',\r\n",
        "    \"verbosity\": logging.INFO,\r\n",
        "    \"n_cross_validations\": 2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "from azureml.train.automl import AutoMLConfig\r\n",
        "\r\n",
        "label = \"TipAmount\"\r\n",
        "\r\n",
        "automl_config = AutoMLConfig(task='regression',\r\n",
        "                             debug_log='automated_ml_errors.log',\r\n",
        "                             training_data = dataset_training,\r\n",
        "                             spark_context = sc,\r\n",
        "                             model_explainability = False, \r\n",
        "                             label_column_name = label,\r\n",
        "                             **automl_settings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## It'll take around 40 mins to fisnish the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Cancel run to save time\r\n",
        "To save time, please go to [AML Studio](https://ml.azure.com/experiments) and cancel your experiment.\r\n",
        "\r\n",
        "![cancel](https://github.com/hyssh/synapse-workshop21/raw/master/images/cancelRun.png)\r\n",
        "\r\n",
        "Remember find your experiment name you defined from the previous cell\r\n",
        "```\r\n",
        "##Replace###-aml-synapse-regression\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Get best model\r\n",
        "\r\n",
        "best_run, fitted_model = local_run.get_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Test best model accuracy\r\n",
        "validation_data_pd = validation_data.toPandas()\r\n",
        "y_test = validation_data_pd.pop(label).to_frame()\r\n",
        "y_predict = fitted_model.predict(validation_data_pd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\r\n",
        "from math import sqrt\r\n",
        "\r\n",
        "# Calculate root-mean-square error\r\n",
        "y_actual = y_test.values.flatten().tolist()\r\n",
        "rmse = sqrt(mean_squared_error(y_actual, y_predict))\r\n",
        "\r\n",
        "print(\"Root Mean Square Error:\")\r\n",
        "print(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Calculate mean-absolute-percent error and model accuracy \r\n",
        "sum_actuals = sum_errors = 0\r\n",
        "\r\n",
        "for actual_val, predict_val in zip(y_actual, y_predict):\r\n",
        "    abs_error = actual_val - predict_val\r\n",
        "    if abs_error < 0:\r\n",
        "        abs_error = abs_error * -1\r\n",
        "\r\n",
        "    sum_errors = sum_errors + abs_error\r\n",
        "    sum_actuals = sum_actuals + actual_val\r\n",
        "\r\n",
        "mean_abs_percent_error = sum_errors / sum_actuals\r\n",
        "\r\n",
        "print(\"Model MAPE:\")\r\n",
        "print(mean_abs_percent_error)\r\n",
        "print()\r\n",
        "print(\"Model Accuracy:\")\r\n",
        "print(1 - mean_abs_percent_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from sklearn.metrics import mean_squared_error, r2_score\r\n",
        "\r\n",
        "# Calculate the R2 score by using the predicted and actual fare prices\r\n",
        "y_test_actual = y_test[label]\r\n",
        "r2 = r2_score(y_test_actual, y_predict)\r\n",
        "\r\n",
        "# Plot the actual versus predicted fare amount values\r\n",
        "plt.style.use('ggplot')\r\n",
        "plt.figure(figsize=(10, 7))\r\n",
        "plt.scatter(y_test_actual,y_predict)\r\n",
        "plt.plot([np.min(y_test_actual), np.max(y_test_actual)], [np.min(y_test_actual), np.max(y_test_actual)], color='lightblue')\r\n",
        "plt.xlabel(\"Actual Tip Amount\")\r\n",
        "plt.ylabel(\"Predicted Tip Amount\")\r\n",
        "plt.title(\"Actual vs Predicted Fare Amount R^2={}\".format(r2))\r\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "description = 'My automated ML model'\r\n",
        "model_path='outputs/model.pkl'\r\n",
        "model = best_run.register_model(model_name = 'NYCGreenTaxiModel', model_path = model_path, description = description)\r\n",
        "print(model.name, model.version)"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}